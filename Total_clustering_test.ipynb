{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c623e4",
   "metadata": {},
   "source": [
    "Vincent Earl Andrews \n",
    "\n",
    "All region test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c690c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "sns.set_context('talk')\n",
    "plt.style.use('default')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from astropy.wcs import wcs\n",
    "from time import sleep\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33904b",
   "metadata": {},
   "source": [
    "Functions used: \n",
    "> open_file : extracts data from fits file, removes Nans and removes 2nd frequency channel.\n",
    "> kmeans : performs clustering \n",
    "> get_galcord : gets galactic coordinates using corresponding moment 0 map\n",
    "> get_coordinates : i dont think i use this \n",
    "> get_centroid_radius : retruns apprximate radius of clump in a circular region about rhe centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c764dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(path):\n",
    "    '''\n",
    "    Function:\n",
    "    path: Used for looping through several fits files with a common naming scheme as shown below\n",
    "    \n",
    "    This function opens fits files from the RAMPS data and extracts the data into a\n",
    "    pandas dataframe\n",
    "        - hdr.set was used to fill in headers that were empty and giving error messages \n",
    "        - the 2nd spectral channel is removed, should only be 1 channel for a map\n",
    "        - nan values were dropped \n",
    "        - \n",
    "    '''\n",
    "    print(\"opening file...\")\n",
    "    hdul = fits.open('D:/hf_vel/'+path+'_NH3_1-1_hf_width.fits')\n",
    "    hdr = hdul[0].header\n",
    "    hdr.set('BLANCK', 'none') # idk why blanck = -1 originally \n",
    "    hdr.set('NAXIS3',1) #i get an error message when this is gone idk\n",
    "    d = hdul[0].data #3D with 2 channels ?\n",
    "    data = np.swapaxes(d,0,2)\n",
    "    hdul.close()\n",
    "    coords = []\n",
    "    values = []\n",
    "    for (i, j, k), value in np.ndenumerate(data):\n",
    "        coords.append((i, j, k))\n",
    "        values.append(value)\n",
    "    df = pd.DataFrame({'Coordinate': coords, 'Value': values})\n",
    "    df[['X', 'Y', 'Z']] = pd.DataFrame(df['Coordinate'].tolist(), index=df.index)\n",
    "    df = df.drop('Coordinate', axis=1)\n",
    "    DF = df.dropna() #removing nan values \n",
    "    #reduce data frame to points of interest \n",
    "    lowHF = DF[(DF['Value'] <=100)]\n",
    "    lowHF_XY = lowHF.drop(columns=[\"Z\",\"Value\"])\n",
    "    return lowHF_XY, lowHF\n",
    "\n",
    "def Kmeans(data, n, region):\n",
    "    print(\"performing clustering...\")\n",
    "    km = KMeans(n_clusters=n,init='k-means++',n_init = 1000, tol = 1e-4)\n",
    "    km.fit(data)\n",
    "    labels = km.predict(data)\n",
    "    centroids = km.cluster_centers_\n",
    "    centroid_centers = km.cluster_centers_\n",
    "    \n",
    "    # This gets the index of each value per clump\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['data_index'] = data.index.values\n",
    "    cluster_map['Cluster'] = labels\n",
    "    new_map = cluster_map.set_index('data_index') # change random index to cluster index\n",
    "\n",
    "    # getting coordinates at each index per clump\n",
    "    # join dataframes where indicies are the same\n",
    "    cords = pd.concat([lowHF,new_map], axis = 1, join = 'inner')\n",
    "    cords.insert(0, 'Region', region)\n",
    "    cords.drop(['Z'], axis = 1) # remove 3rd axis\n",
    "    \n",
    "    columns  = ['Region', 'Cluster', 'Value','X','Y']\n",
    "    ordered_cords = cords[columns]\n",
    "    #print(ordered_cords)\n",
    "    #print(len(ordered_cords))\n",
    "    # yeah it works 0_0 this gives the centorid number each point is assigned to\n",
    "    return labels, centroids, centroid_centers, ordered_cords\n",
    "\n",
    "def get_galcord(filepath):\n",
    "    '''\n",
    "    Definition:\n",
    "    filepath: naming scheme for mom0 files follows the mom0_head variable below \n",
    "    mom0: The moment zero map is the total integrated intensity of the \n",
    "    spectral line being observed as some frequency, f.\n",
    "    \n",
    "    Function:\n",
    "    Computes the galactic coordinates (GLON and GLAT) and the right ascension, \n",
    "    declination coordinates alongside the pixel coordinates for the center of \n",
    "    each clump found\n",
    "    '''\n",
    "    print(\"getting galactic cooridnates...\")\n",
    "    mom0_head = fits.getheader('D:/hf_vel/'+filepath+'_NH3_1-1_mom0.fits')\n",
    "    #using world coordinates system conversion (for all points)\n",
    "    w = wcs.WCS(mom0_head)\n",
    "    sky = w.pixel_to_world(lowHF.X, lowHF.Y)\n",
    "    equ = sky.transform_to('icrs')\n",
    "    lowHF['GLON'] = sky.l.value\n",
    "    lowHF['GLAT'] = sky.b.value\n",
    "    lowHF['RA'] = equ.ra.value\n",
    "    lowHF['DEC'] = equ.dec.value\n",
    "    \n",
    "    #using wcs for conversion of center points only\n",
    "    df_cent = pd.DataFrame(centroids, columns=['x_center', 'y_center'])\n",
    "    sky = w.pixel_to_world(df_cent.x_center, df_cent.y_center)\n",
    "    equ_cent = sky.transform_to('icrs')\n",
    "    #creating galactic coordinate dataframe \n",
    "    df_cent['GLON'] = sky.l.value\n",
    "    df_cent['GLAT'] = sky.b.value\n",
    "    df_cent['RA'] = equ_cent.ra.value\n",
    "    df_cent['DEC'] = equ_cent.dec.value\n",
    "    \n",
    "    '''\n",
    "    Returns Dataframe:\n",
    "    columns = [x_center, y_center, GLON, GLAT, RA, DEC]\n",
    "    length of number of clumps per region, L. Total length should be number of clumps\n",
    "    across all regions\n",
    "    '''\n",
    "    return df_cent\n",
    "\n",
    "def get_centroid_radius(X,Y,center_hk):\n",
    "    '''\n",
    "    This function takes (X, Y): the pixel position of every point within a clump\n",
    "    and center_hk: the center coordinate of the clump\n",
    "    \n",
    "    The radius is then computed for every set of points from the \n",
    "    2D distance formula\n",
    "    \n",
    "    The average distance is then selected as the clump radius, This works fine \n",
    "    if the clump is spherical\n",
    "    '''\n",
    "    print(\"Calculating radius of clumps...\")\n",
    "    possible_radii = [] # stores all radius values calculated\n",
    "    h = center_hk[0] # h is x center cord, k is y center cord\n",
    "    k = center_hk[1]\n",
    "    \n",
    "    # compute distance for each point to the center\n",
    "    for x_pos in X:\n",
    "        for y_pos in Y:\n",
    "            d = np.sqrt((x_pos-h)**2+(y_pos-k)**2)\n",
    "            possible_radii.append(d)  \n",
    "    # get \n",
    "    rr = max(possible_radii)\n",
    "    radii.append(rr)\n",
    "    #yeahhhhhh it worked (:\n",
    "    return radii\n",
    "\n",
    "def jeans_mass_T(c):\n",
    "    # c is the cords df containing all cords in each centroid \n",
    "    '''\n",
    "    Definition:\n",
    "    Jeans critical mass: The mass of a clump of gas at which gravitational energy exceeds\n",
    "    the outward turbulence/pressure. At this mass, the cloud of gas will likely collapse\n",
    "    to form a star.\n",
    "    \n",
    "    Function:\n",
    "    Calculates the critical Jeans mass of a clump\n",
    "    The equation for this depends on gas temperature\n",
    "        T: Gas temperature [K]\n",
    "        m: mass of particle in gas [kg]\n",
    "        n: gas number = density/mean mass per particle [?]\n",
    "        k: boltzman constant\n",
    "        G: Gravitational constant \n",
    "    '''\n",
    "    return ((375 * k**3) / (4 * pi * m**4 * G**3)) * (T**3 / n)**(1/3)\n",
    "\n",
    "def jeans_mass_hf():\n",
    "    '''\n",
    "    Calculates the critical Jeans mass of a clump\n",
    "    The equation for this depends on the sound speed, cs\n",
    "        cs: sound speed of ammonia \n",
    "        rho: density\n",
    "        G: Gravitational constant \n",
    "    '''\n",
    "    return (pi/6) * ((cs**3) / (G**(3/2) * rho**(1/2)))\n",
    "    \n",
    "def ammonia_mass():\n",
    "    '''\n",
    "    Definition: \n",
    "    The clump mass can be determined by looking at abundance ratios of different elements \n",
    "    in our target region. Molecular hydrogen is one of the most abundance; therefore,\n",
    "    we can look at the abudnace of ammonia wrt to hydrogen to roughly estimate the mass.\n",
    "    \n",
    "    Function:\n",
    "    Calculates the clump mass using abundance ratios between\n",
    "    hydrogen and ammonia\n",
    "        mu: molecular weight per hydrogen \n",
    "        mH: atomic hydrogen mass\n",
    "        **Apix: area of a pixel in physical coordinates** need distance resolved \n",
    "        N_NH3: ammonia column density\n",
    "        **X_NH3: ammonia abundance wrt hydrogen** need to find   \n",
    "    '''\n",
    "    mu = 2.8 # kauffmann et al 2009\n",
    "    mH = 1.6735575e-27 # [kg]\n",
    "    \n",
    "    # get mass per pixel\n",
    "    M = 0\n",
    "    \n",
    "    # multiply by how many pixel in each cluster\n",
    "    # get how many regions have clump designation, N, \n",
    "    # then multiply pixel mass times num of pixels\n",
    "    \n",
    "    # get mass in solar masses \n",
    "    Msun = 1.91e30 # mass of sun [kg]\n",
    "    clump_masses = [] # list of all clump masses\n",
    "    clump_mass = M / Msun\n",
    "    \n",
    "def avg_hf():\n",
    "    '''\n",
    "    This calculates the average hyperfine width of ammonia per clump\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f3ccca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n",
      "opening file...\n",
      "performing clustering...\n",
      "getting galactic cooridnates...\n",
      "Saving Figure \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coordinates for center of each clump \n",
    "CENT_LON = []\n",
    "CENT_LAT = []\n",
    "\n",
    "all_clump_designations = pd.DataFrame() # this stores all clump cords and their centroid number\n",
    "'''\n",
    "paths = ['L47','L43','L41','L40_5','L40','L39_5','L39','L38_5','L38','L37_5',\n",
    "          'L37','L36_5','L36','L35_5','L35','L34_5','L34','L33_5','L33','L32_5'\n",
    "          ,'L32','L31_5','L31','L30_5','L30','L29_5','L29','L28_5','L28','L27_5'\n",
    "          ,'L27','L26_5','L26','L25_5','L25','L24_5','L24','L23_5','L23','L22_5'\n",
    "          ,'L22','L21_5','L21','L20_5','L20','L19_5','L19','L18_5','L18','L17_5','L17',\n",
    "          'L16_5','L15_5','L15','L14_5','L14','L13_5','L13','L12_5','L12',\n",
    "          'L11_5','L11','L10_5','L10']\n",
    "'''\n",
    "paths = ['L19_5','L19','L18_5','L18','L17_5','L17',\n",
    "          'L16_5','L15_5','L15','L14_5','L14','L13_5','L13','L12_5','L12',\n",
    "          'L11_5','L11','L10_5','L10']\n",
    "\n",
    "n_regions = len(path)\n",
    "for L in paths:\n",
    "    # PART 1: Opening file and processing data\n",
    "    '''\n",
    "    final_n = [6,16,6,7,5,6,23,26,26,26,26,42,62,40,41,\n",
    "                41,3,25,19,15,69,50,93,89,93,80,39,92,60,40,30\n",
    "                ,98,35,39,88,80,93,92,99,9,6,17,19,11,16,84,74,\n",
    "                49,2,5,33,41,8,60,60,40,35,35,50,30,18,40,40,20]\n",
    "    '''\n",
    "    final_n = [84,74,49,2,5,33,41,8,60,60,40,35,35,50,30,18,40,40,20]\n",
    "    i = paths.index(L)\n",
    "    # usually final_n is a list corresponding to each path\n",
    "    n = final_n[i]\n",
    "    lowHF_XY, lowHF = open_file(L) \n",
    "  \n",
    "    # PART 2: Performing clustering\n",
    "    labels, centroids, centroid_centers, clump_designations = Kmeans(lowHF_XY,n, L) # centroid_centers are in pixel cords here\n",
    "    #clump_radius = get_centroid_radius()\n",
    " \n",
    "    # PART 3: Extract coordinates of clumps\n",
    "    df_centroids = get_galcord(L) # df_centroids has XY, RA/DEC, l/b\n",
    " \n",
    "    # PART 4: Plotting\n",
    "    cmap = 'viridis' #colormap \n",
    "    \n",
    "    #axis 2 is the galactic coordinates \n",
    "    plt.scatter(lowHF.GLON, lowHF.GLAT,s = 500, c=labels, cmap=cmap, vmin = 0, vmax = max(labels) * 1.3)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.scatter(df_centroids.GLON, df_centroids.GLAT, marker='*', c='gold', alpha=1, s=800,edgecolor = 'black', label = 'Clump Centers')\n",
    "    # idk what this is but im scared of deleting stuff\n",
    "    #for i in range(df_centroids.shape[0]): #this numbers points \n",
    "    #  plt.scatter(df_centroids.GLON[i], df_centroids.GLAT[i], marker='$%d$' % i, s=40, edgecolor ='darkorchid')\n",
    "    f = 48\n",
    "    font = {'fontname':'Calibri'}\n",
    "    plt.xlabel('Galactic Longitude', fontsize = f, **font)\n",
    "    plt.ylabel('Galactic Latitude', fontsize = f, **font)\n",
    "    plt.legend(prop = { \"size\": f-12 })\n",
    "    plt.title(\"Region \"+L+\": Gas Clump Distribution\", fontsize = f, **font)\n",
    "    plt.xticks(fontsize=f)\n",
    "    plt.yticks(fontsize=f)\n",
    "    #need to invert image so longitude reflects hyperfine width image\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(24,16)\n",
    "    print(\"Saving Figure\", '\\n')\n",
    "    plt.savefig('D:/clustering_plots/'+L+'clustering.png')\n",
    "    plt.clf()\n",
    "    '''\n",
    "       # PART 5: Exporting data\n",
    "    latcord = df_centroids.RA.tolist()\n",
    "    loncord = df_centroids.DEC.tolist()\n",
    "    for la in latcord:\n",
    "        CENT_LAT.append(la)\n",
    "    for lo in loncord:\n",
    "        CENT_LON.append(lo)\n",
    "    '''\n",
    "    # append to all clump dataframe  \n",
    "    all_clump_designations = pd.concat([all_clump_designations, clump_designations], ignore_index=True)\n",
    "\n",
    "all_clump_designations.to_csv(\"D:/clump_designations/cutoff.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a32d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting coordinates to csv\n",
      "           LON        LAT\n",
      "0   273.888013 -17.648951\n",
      "1   273.628218 -17.854243\n",
      "2   273.487630 -17.489670\n",
      "3   273.460620 -18.030340\n",
      "4   273.041078 -17.677414\n",
      "..         ...        ...\n",
      "57  273.433127 -17.194529\n",
      "58  273.694373 -17.545121\n",
      "59  273.616267 -17.736206\n",
      "60  273.558070 -17.919612\n",
      "61  273.405371 -17.309312\n",
      "\n",
      "[62 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# PART 5: Exporting data to csv\n",
    "print(\"extracting coordinates to csv\")\n",
    "clmns = ['LON','LAT']\n",
    "CENT_ALL = pd.DataFrame(list(zip(CENT_LAT,CENT_LON)),columns = clmns)\n",
    "# uncomment to save csv file\n",
    "CENT_ALL.to_csv('C:/Users/vince/Desktop/AmmoniaHF/data/L13_cords_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30031aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCODING GRAVEYARD  <3\\n\\ndef get_coordinates(Data,data_labels,centroid_num,center):\\n    # this function should get the coordinates of all points for each clump\\n    # need to do this before getting average hf_wdith and Ntot\\n    print(\"getting clump center cooridnates...\")\\n    l = [].clear()\\n    b = [].clear()\\n    coordinates = lowHF[labels == centroid_num]\\n    #l = coordinates[\\'GLON\\'].values.tolist()\\n    #b = coordinates[\\'GLAT\\'].values.tolist()\\n    #coordinate_dictionary[\"Xcord\"+str(centroid_num)] = X_cord\\n    #coordinate_dictionary[\"Ycord\"+str(centroid_num)] = Y_cord\\n    #get_centroid_radius(l,b,center)\\n    return coordinates\\n\\n\\n    def get_coordinates(data_labels,centroid_num):\\n    # this function should get the coordinates of all points for each clump\\n    # need to do this before getting average hf_wdith and Ntot\\n    print(\"getting clump center cooridnates...\")\\n    l = [].clear()\\n    b = [].clear()\\n    coordinates = lowHF[data_labels == centroid_num] # idk if this works\\n    hf = coordinates[\\'value\\'].values.tolist()\\n    x = coordinates[\\'X\\'].values.tolist()\\n    y = coordinates[\\'Y\\'].values.tolist()\\n    \\n    print(hf)\\n    print(statistics.mean(hf))\\n    #coordinate_dictionary[\"Xcord\"+str(centroid_num)] = X_cord\\n    #coordinate_dictionary[\"Ycord\"+str(centroid_num)] = Y_cord\\n    #get_centroid_radius(l,b,center)\\n    return coordinates\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CODING GRAVEYARD  <3\n",
    "\n",
    "def get_coordinates(Data,data_labels,centroid_num,center):\n",
    "    # this function should get the coordinates of all points for each clump\n",
    "    # need to do this before getting average hf_wdith and Ntot\n",
    "    print(\"getting clump center cooridnates...\")\n",
    "    l = [].clear()\n",
    "    b = [].clear()\n",
    "    coordinates = lowHF[labels == centroid_num]\n",
    "    #l = coordinates['GLON'].values.tolist()\n",
    "    #b = coordinates['GLAT'].values.tolist()\n",
    "    #coordinate_dictionary[\"Xcord\"+str(centroid_num)] = X_cord\n",
    "    #coordinate_dictionary[\"Ycord\"+str(centroid_num)] = Y_cord\n",
    "    #get_centroid_radius(l,b,center)\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "    def get_coordinates(data_labels,centroid_num):\n",
    "    # this function should get the coordinates of all points for each clump\n",
    "    # need to do this before getting average hf_wdith and Ntot\n",
    "    print(\"getting clump center cooridnates...\")\n",
    "    l = [].clear()\n",
    "    b = [].clear()\n",
    "    coordinates = lowHF[data_labels == centroid_num] # idk if this works\n",
    "    hf = coordinates['value'].values.tolist()\n",
    "    x = coordinates['X'].values.tolist()\n",
    "    y = coordinates['Y'].values.tolist()\n",
    "    \n",
    "    print(hf)\n",
    "    print(statistics.mean(hf))\n",
    "    #coordinate_dictionary[\"Xcord\"+str(centroid_num)] = X_cord\n",
    "    #coordinate_dictionary[\"Ycord\"+str(centroid_num)] = Y_cord\n",
    "    #get_centroid_radius(l,b,center)\n",
    "    return coordinates\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
